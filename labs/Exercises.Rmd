---
title: "Lab sessions"
author: "Rob J Hyndman"
date: "26 July 2018"
output:
  html_document:
    fig_height: 5
    fig_width: 8
    toc: yes
    toc_depth: 1
    toc_float:
      collapsed: false
    number_sections: false
    theme: readable
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, messages=FALSE, warnings=FALSE)
library(fpp2)
```

# Lab Session 4

```{r lab4}
beer <- window(ausbeer, start=1992)
fc <- snaive(beer)
autoplot(fc)
res <- residuals(fc)
autoplot(res)
```

```{r lab4b, dependson='lab4'}
checkresiduals(fc)
```

There is some remaining autocorrelation in the residuals: the Null of no joint autocorrelation is clearly rejected. We can also see a significant spike on the seasonal (4th lag) in the ACF. There is considerable information remaining in the residuals which has not been captured with the seasonal naÃ¯ve method. The residuals do not appear to be too far from Normally distributed.


# Lab Session 5

```{r lab5, dependson='retail'}
train <- window(mytimeseries, end=c(2010,12))
test <- window(mytimeseries, start=2011)
autoplot(cbind(Training=train,Test=test))
f1 <- snaive(train, h=length(test))
autoplot(f1) + autolayer(test)
accuracy(f1, test)
```

The number to look at here is the test set RMSE. That provides a benchmark for comparison when we try other models.

```{r lab5b, dependson='lab5'}
checkresiduals(f1)
```

The residuals do not look like white noise there are lots of dynamics left over that need to be explored. They also do not look close to normal, with very long tails.

The accuracy measure are always sensitive to the training/test split. There are better ways to check the robustness of the methods in terms of accuracy such as using a `tsCV()`.


# Lab Session 6

```{r lab6, dependson='retail'}
e_mean <- tsCV(mytimeseries, meanf)
e_naive <- tsCV(mytimeseries, naive)
e_snaive <- tsCV(mytimeseries, snaive)
e_drift <- tsCV(mytimeseries, rwf, drift=TRUE)

# Construct squared CV errors matrix
e2 <- cbind(Mean=e_mean^2, Naive=e_naive^2,
	    SNaive=e_snaive^2, Drift=e_drift^2)
# Remove rows with any missing for a fair comparison
e2 <- na.omit(e2)
# Find MSE values
colMeans(e2)
```

# Lab Session 10

```{r lab10, dependson='retail'}
train <- window(mytimeseries, end=c(2010,12))
test <- window(mytimeseries, start=2011)

f1 <- snaive(train, h=length(test))
f2 <- rwf(train, h=length(test))
f3 <- rwf(train, drift=TRUE, h=length(test))
f4 <- meanf(train, h=length(test))
f5 <- hw(train, h=length(test),
         seasonal='multiplicative')
f6 <- ets(train) %>% forecast(h=length(test))

c(
  SNaive=accuracy(f1, test)[2,"RMSE"],
  Naive=accuracy(f2, test)[2,"RMSE"],
  Drift=accuracy(f3, test)[2,"RMSE"],
  Mean=accuracy(f4, test)[2,"RMSE"],
  HW=accuracy(f5, test)[2,"RMSE"],
  ETS=accuracy(f6, test)[2,"RMSE"])
```

These results might depend on the peculiarities of the test set. That's why we usually prefer to do a cross-validation approach where we have many test sets.

```{r lab10b, dependson='retail'}
e1 <- tsCV(mytimeseries, snaive, h=12)
e2 <- tsCV(mytimeseries, naive, h=12)
e3 <- tsCV(mytimeseries, rwf, drift=TRUE, h=12)
e4 <- tsCV(mytimeseries, meanf, h=12)
e5 <- tsCV(mytimeseries, hw,
          seasonal='multiplicative', h=12)
etsfc <- function(y,h,...)
{
  ets(y,...) %>% forecast(h=h)
}
e6 <- tsCV(mytimeseries, etsfc, h=12, model="MAM", damped=TRUE)

MSE <- cbind(
  h=1:12,
  SNaive=colMeans(tail(e1^2, -14)^2, na.rm=TRUE),
  Naive=colMeans(tail(e2^2, -14)^2, na.rm=TRUE),
  Drift=colMeans(tail(e3^2, -14)^2, na.rm=TRUE),
  Mean = colMeans(tail(e4^2, -14)^2, na.rm=TRUE),
  HW=colMeans(tail(e5^2, -14)^2, na.rm=TRUE),
  ETS=colMeans(tail(e6^2, -14)^2, na.rm=TRUE))

MSE
colMeans(sqrt(MSE[,-1]))
```

Here I have simply removed the first 14 rows to ensure we have complete forecasts for all times. It might be better to remove the first few years, to avoid the problem of having unreliable forecasts when the training data is too short.

Finally, we do the calculation allowing `ets` to select a different model every time.

```{r lab10c, dependson='lab10b'}
e7 <- tsCV(mytimeseries, etsfc, h=12)

MSE <- cbind(MSE,
  ETS2 = colMeans(tail(e7^2, -14), na.rm=TRUE))
MSE
colMeans(sqrt(MSE[,-1]))
```


# Lab Session 11


```{r lab10a}
autoplot(usnetelec)
```

No transformation required

```{r lab10b}
autoplot(mcopper)
(lambda <- BoxCox.lambda(mcopper))
mcopper %>% BoxCox(lambda=0) %>% autoplot
```

```{r lab10c}
autoplot(enplanements)
(lambda <- BoxCox.lambda(enplanements, lower=0))
# I don't like such strong transformations. Will use 0 instead
enplanements %>% BoxCox(lambda=0) %>% autoplot
```

```{r lab10d}
autoplot(a10)
(lambda <- BoxCox.lambda(a10))
a10 %>% BoxCox(lambda=lambda) %>% autoplot
a10 %>% BoxCox(lambda=0) %>% autoplot
```

```{r lab10e}
autoplot(cangas)
```

```{r retail}
retaildata <- read.csv("retail.csv")
mytimeseries <- ts(retaildata[,4], frequency=12, start=c(1982,4))
(lambda <- BoxCox.lambda(mytimeseries, lower=0))
# Essentially a log
mytimeseries %>% log() %>% autoplot()
```


# Lab Session 15

```{r lab15a}
usnetelec %>% autoplot()
usnetelec %>% ndiffs()
usnetelec %>% diff() %>% autoplot()
```

```{r lab15b}
usgdp %>% autoplot()
ndiffs(usgdp)
usgdp %>% diff(differences=2) %>% autoplot()
```

```{r lab15c}
lambda <- BoxCox.lambda(mcopper)
mcopper %>% BoxCox(lambda=lambda) %>% autoplot()
mcopper %>% BoxCox(lambda=lambda) %>% nsdiffs()
mcopper %>% BoxCox(lambda=lambda) %>% ndiffs()
mcopper %>% BoxCox(lambda=lambda) %>% diff(lag=1) %>% autoplot()
```

```{r lab15d}
enplanements %>% log() %>% autoplot()
enplanements %>% log() %>% nsdiffs()
enplanements %>% log() %>% diff(lag=12) %>% autoplot()
enplanements %>% log() %>% diff(lag=12) %>% ndiffs()
enplanements %>% log() %>% diff(lag=12) %>% diff() %>% autoplot()
```

```{r lab15e}
visitors %>% autoplot()
lambda <- BoxCox.lambda(visitors)
visitors %>% BoxCox(lambda=lambda) %>% autoplot()
visitors %>% BoxCox(lambda=lambda) %>% nsdiffs()
visitors %>% BoxCox(lambda=lambda) %>% diff(lag=12) %>% autoplot()
visitors %>% BoxCox(lambda=lambda) %>% diff(lag=12) %>% ndiffs()
visitors %>% BoxCox(lambda=lambda) %>% diff(lag=12) %>% diff() %>% autoplot
```

```{r lab15f, dependson='retail'}
mytimeseries %>%
  BoxCox(lambda=0) %>% nsdiffs()
mytimeseries %>%
  BoxCox(lambda=0) %>%
  diff(lag=12) %>% ndiffs()
mytimeseries %>%
  BoxCox(lambda=0) %>%
  diff(lag=12) %>%
  diff(lag=1) %>%
  autoplot()
```

# Lab Session 16

```{r lab16}
wmurders %>% autoplot()
wmurders %>% log() %>% autoplot()
fit <- auto.arima(wmurders, lambda=0)
checkresiduals(fit)
forecast(fit) %>% autoplot()
wmurders %>% ets() %>% forecast() %>% autoplot()
wmurders %>% ets(lambda=0, model="AAN") %>% forecast() %>% autoplot()
```

# Lab Session 17


```{r lab17, dependson='lab14b'}
lambda <- 0
(arimamod1 <- auto.arima(train, lambda=lambda))
(arimamod2 <- auto.arima(train,
              lambda=lambda,
              stepwise=FALSE,
              approximation=FALSE))
checkresiduals(arimamod1)
checkresiduals(arimamod2)
arimamod1 %>% forecast(h=length(test)) %>% autoplot()
arimamod2 %>% forecast(h=length(test)) %>% autoplot() + autolayer(test, series="Test")
```

```{r lab17b, dependson='lab17'}
(etsmod <- ets(train))

f1 <- snaive(train, h=length(test))
f2 <- hw(train, h=length(test), seasonal='multi')
f3 <- forecast(etsmod, h=length(test))
f4 <- stlf(train, lambda=lambda, h=length(test))
f5 <- forecast(arimamod1, h=length(test))
f6 <- forecast(arimamod2, h=length(test))
```

```{r lab17d}
c(
  SNaive=accuracy(f1,test)["Test set","RMSE"],
  HW=accuracy(f2,test)["Test set","RMSE"],
  ETS=accuracy(f3,test)["Test set","RMSE"],
  STLF=accuracy(f4,test)["Test set","RMSE"],
  ARIMAmod1=accuracy(f5,test)["Test set","RMSE"],
  ARIMAmod2=accuracy(f6,test)["Test set","RMSE"])
```

```{r lab17e}
autoplot(f6) +
  autolayer(test, series="New data")
```

```{r lab17f}
autoplot(hsales)
mod <- auto.arima(hsales,
                  stepwise=FALSE,
                  approximation = FALSE)
checkresiduals(mod)
mod %>% forecast() %>% autoplot()
hsales %>% ets() %>% forecast %>% autoplot()
```

# Lab Session 18

```{r lab18a, dependson="lab17"}
arimafc <- function(y,h)
{
  y %>% Arima(order=c(1,1,0), seasonal=c(2,1,2), lambda=0) %>% forecast(h=h)
}
e <- tsCV(mytimeseries, arimafc, h=12)

colMeans(tail(e^2, -14), na.rm=TRUE) %>% sqrt()

mean(tail(e^2, -14), na.rm=TRUE) %>% sqrt()

ggtsdisplay(e[,1])
```

```{r lab18b, dependson='retail'}
etsfc <- function(y,h)
{
  ets(y) %>% forecast(h=h)
}
arimafc <- function(y,h)
{
  auto.arima(y, lambda=0) %>% forecast(h=h)
}
e1 <- tsCV(mytimeseries, etsfc, h=12)
e2 <- tsCV(mytimeseries, arimafc, h=12)
MSE <- cbind(
  ETS = colMeans(tail(e1^2, -14), na.rm=TRUE),
  ARIMA = colMeans(tail(e2^2, -14), na.rm=TRUE))
colMeans(sqrt(MSE))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, messages=FALSE, warnings=FALSE)
library(fpp2)
```

# Lab Session 21


```r
# Find the order of Fourier terms which gives minimum AIC
bestmodel <- list(aicc=Inf)
for(k in seq(26)) {
  fit <- auto.arima(gastrain,
    xreg=fourier(gastrain, K=k))
  if(fit$aicc < bestmodel$aicc) {
    bestmodel <- fit
    bestK <- k
  }
}
fc3 <- forecast(bestmodel, xreg=fourier(gastrain, bestK, 24))
accuracy(fc3, gastest)
```

# Lab Session 22

```{r lab22a, fig.height=8}
library(hts)
head(infantgts$bts)
plot(infantgts)
smatrix(infantgts)

# Forecast 10-steps-ahead and reconcile the forecasts
infantforecast <- forecast(infantgts, h=10)

# Plot the forecasts including only the last ten historical years
plot(infantforecast, include=10)

# set up training and testing sets
training <- window(infantgts, end=1993)
test <- window(infantgts, start=1994)

# Compute forecasts on training data
forecast <- forecast(training, h=10)

# calculate ME, RMSE, MAE, MAPE, MPE and MASE
accuracy.gts(forecast, test)
```

```{r lab22b}
# Overall forecast accuracy
rmse <- accuracy(forecast, test)["RMSE",]
sqrt(sum(rmse^2))
```

```{r lab22c}
forecast_bu <- forecast(training, h=10, method="bu")
sqrt(sum(accuracy(forecast_bu, test)["RMSE",]^2))
```

